{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f84e7b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_classic.embeddings import CacheBackedEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "from langchain_classic.storage import LocalFileStore\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    streaming=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55de1afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 37\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader(\"./document.txt\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=text_splitter)\n",
    "\n",
    "print(f\"Number of documents: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ed3da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    ")\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings,\n",
    "    cache_dir,\n",
    "    key_encoder=lambda text: hashlib.sha256(text.encode(\"utf-8\")).hexdigest(),\n",
    ")\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=cached_embeddings,\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24468276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trace\\AppData\\Local\\Temp\\ipykernel_11088\\3384409080.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True,\n",
    "    memory_key=\"history\",\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer questions using only the context. If you don't know the answer, just say you don't know; don't make it up.:\\n\\n{context}\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def load_memory(input):\n",
    "    print(input)\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"history\": load_memory,\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e07c8e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_chain(question):\n",
    "    result = chain.invoke(question)\n",
    "    answer = result.content\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": answer},\n",
    "    )\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f44079b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Aaronson guilty?\n",
      "According to the context, Aaronson is guilty of the crimes he was charged with.According to the context, Aaronson is guilty of the crimes he was charged with.\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Is Aaronson guilty?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12c2e8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What message did he write in the table?\n",
      "He wrote \"I sold you and you sold me\" on the table under the spreading chestnut tree.He wrote \"I sold you and you sold me\" on the table under the spreading chestnut tree.\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What message did he write in the table?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1145fc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is Julia?\n",
      "Julia is a character with whom Winston has a romantic relationship. She is someone he loves and is deeply connected to, despite the oppressive regime they live under.Julia is a character with whom Winston has a romantic relationship. She is someone he loves and is deeply connected to, despite the oppressive regime they live under.\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Who is Julia?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
